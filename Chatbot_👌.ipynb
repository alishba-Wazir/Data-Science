{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-hYedMZ2Abu",
        "outputId": "2c035a6e-1705-4508-ec8b-7906ca058ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers colorama #print colored text in the terminal\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from colorama import Fore, Style, init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxLbqSCqFoS5",
        "outputId": "9458ecc6-c76d-4bd8-91c9-1e941a955682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Initialize models (optimize by initializing once and reusing)\n",
        "\n",
        "def load_models():\n",
        "    models = {\n",
        "        \"essay\": pipeline(\"text-generation\", model=\"gpt2\", device=device),\n",
        "        \"poetry\": pipeline(\"text-generation\", model=\"gpt2\", device=device),\n",
        "        \"summary\": pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device),\n",
        "        \"faq\": pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\", device=device),\n",
        "    }\n",
        "    return models\n",
        "\n",
        "models = load_models()"
      ],
      "metadata": {
        "id": "T-z7m1ru36cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Initialize colorama\n",
        "init(autoreset=True)\n",
        "\n",
        "# Check for GPU availability\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate text based on task type\n",
        "def generate_text(input_text, task_type, max_length):\n",
        "    try:\n",
        "        if task_type == 'Essay':\n",
        "            prompt = f\"Write an essay on {input_text}\"\n",
        "            response = models[\"essay\"](prompt,max_length=max_length,num_return_sequences=1)\n",
        "            return response[0]['generated_text']\n",
        "\n",
        "        elif task_type == 'Poetry':\n",
        "            prompt = f\"Write a poem on {input_text}\"\n",
        "            response = models[\"poetry\"](prompt,max_length=max_length,num_return_sequences=1)\n",
        "            return response[0]['generated_text']\n",
        "\n",
        "        elif task_type == 'Summary':\n",
        "            response = models[\"summary\"](input_text,max_length=max_length,min_length=max_length//2,do_sample=False)\n",
        "            return response[0]['summary_text']\n",
        "\n",
        "        elif task_type == 'FAQ':\n",
        "            prompt = f\"Generate a FAQ for {input_text}\"\n",
        "            response = models[\"faq\"](prompt,max_length=max_length,num_return_sequences=1)\n",
        "            return response[0]['generated_text']\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"  # Return an error message string\n",
        "\n",
        "# Function to handle user input\n",
        "def get_user_input():\n",
        "    print(\"📝 AI Text Generator\")\n",
        "    print(\"Generate Essays, Poetry, Summaries, or FAQs with ease!\\n\")\n",
        "\n",
        "    task_type = input(\"🎯 Select Task Type (Essay, Poetry, Summary, FAQ): \")\n",
        "    input_text = input(\"✍️ Enter the Topic or Text: \")\n",
        "\n",
        "    # Ensure max_length is a valid integer input\n",
        "    while True:\n",
        "        try:\n",
        "            max_length = int(input(\"🔢 Enter the Desired Length of Content (in characters, between 50 and 1000): \"))\n",
        "            if max_length < 50 or max_length > 1000:\n",
        "                print(\"Please enter a value between 50 and 1000.\")\n",
        "            else:\n",
        "                return task_type, input_text, max_length  # Return user inputs\n",
        "        except ValueError:\n",
        "            print(\"Invalid input! Please enter a numeric value.\")\n",
        "\n",
        "# Main function to generate text based on user input\n",
        "def main():\n",
        "    history = []  # List to keep track of history\n",
        "    while True:\n",
        "        task_type, input_text, max_length = get_user_input()  # Get user input\n",
        "        generated_output = generate_text(input_text, task_type, max_length)\n",
        "\n",
        "        # Store the input and generated output in history\n",
        "        history.append((task_type, input_text, generated_output))\n",
        "\n",
        "        # Display the generated output\n",
        "        print(\"\\nGenerated Output:\")\n",
        "        print(generated_output)\n",
        "\n",
        "        if input(\"\\nDo you want to generate more text? (yes/no): \").strip().lower() != 'yes':\n",
        "            break\n",
        "\n",
        "    # Display history when the user exits\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(Fore.CYAN + \"     🗒️ History of Generated Text     \")\n",
        "    print(\"=\" * 40 + \"\\n\")\n",
        "\n",
        "    for i, entry in enumerate(history, 1):\n",
        "        task, text, output = entry\n",
        "        output_display = output if isinstance(output, str) else \"Error occurred while generating output.\"\n",
        "\n",
        "        # Display with borders and enhanced formatting\n",
        "        print(Fore.YELLOW + f\"Entry {i}:\")\n",
        "        print(Fore.GREEN + \"-\" * 40)\n",
        "        print(Fore.MAGENTA + f\"Task Type: {task}\")\n",
        "        print(Fore.MAGENTA + f\"Input Text: {text}\")\n",
        "        print(Fore.MAGENTA + f\"Generated Output: {output_display[:100]}...\")  # Display first 100 chars of output\n",
        "        print(Fore.GREEN + \"-\" * 40)\n",
        "\n",
        "# Call the main function to run the program\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJlOchJvEOR0",
        "outputId": "2425e4fc-4f80-4080-a2bc-b11893f43bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📝 AI Text Generator\n",
            "Generate Essays, Poetry, Summaries, or FAQs with ease!\n",
            "\n",
            "🎯 Select Task Type (Essay, Poetry, Summary, FAQ): Summary\n",
            "✍️ Enter the Topic or Text: Rain\n",
            "🔢 Enter the Desired Length of Content (in characters, between 50 and 1000): 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 600, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Output:\n",
            "Rain forecast for the next few days. Rain is expected to continue through the end of the month. Rain could fall as far south as New York City and Long Island. Rain may also fall in parts of New Jersey and New England. Rain and thunderstorms are forecast for next week and into next week. rain is also expected to fall in some areas of New York and New Jersey. Rain can also be seen in other parts of the U.S. and parts of Canada. The rain is forecast to continue into the next week or so, with the possibility of thunderstorms and showers in the next two weeks. The weather could also be expected to be wet in New York, New England, and the South on Wednesday and Thursday. The forecast is for rain and thunder in the coming days and then sunshine on Friday and Saturday. For more information, go to www.cnn.com/rain and www.nyc.gov/news/local/stories/rain-and-storms-in-the-north-east-of-new-years-weekend-rain-may-be-occurring-through-next-week.html. For the full forecast, visit CNN.com/. For the latest on the National Weather Service's coverage of the weather in the United States, call the National Hurricane Center at 1-800-273-8255 or go to http://www.nhw.org/NWS/News/Local/Impact/Impacted-Rain/In-New-Initiations.\n",
            "\n",
            "Do you want to generate more text? (yes/no): yes\n",
            "📝 AI Text Generator\n",
            "Generate Essays, Poetry, Summaries, or FAQs with ease!\n",
            "\n",
            "🎯 Select Task Type (Essay, Poetry, Summary, FAQ): Essay\n",
            "✍️ Enter the Topic or Text: Ai uses\n",
            "🔢 Enter the Desired Length of Content (in characters, between 50 and 1000): 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Output:\n",
            "Write an essay on Ai uses a computer to do it. I won't get into how it is the right format, but I will note that some people choose to write \"Ai on the Internet\", which is a computer program that sends \"I'm on the Internet with Google Maps\" to their Gmail account before posting it on the blog. This\n",
            "\n",
            "Do you want to generate more text? (yes/no): no\n",
            "\n",
            "========================================\n",
            "     🗒️ History of Generated Text     \n",
            "========================================\n",
            "\n",
            "Entry 1:\n",
            "----------------------------------------\n",
            "Task Type: Summary\n",
            "Input Text: Rain\n",
            "Generated Output: Rain forecast for the next few days. Rain is expected to continue through the end of the month. Rain...\n",
            "----------------------------------------\n",
            "Entry 2:\n",
            "----------------------------------------\n",
            "Task Type: Essay\n",
            "Input Text: Ai uses\n",
            "Generated Output: Write an essay on Ai uses a computer to do it. I won't get into how it is the right format, but I wi...\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}